{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = \"./data/\"\n",
    "sp_data_path = data_path + \"SP-train.npy\"\n",
    "wp_data_path = data_path + \"WP-train.npy\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/qianqi/.conda/envs/nlp243/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from transformers import BertForQuestionAnswering\n",
    "from transformers import BertTokenizer\n",
    "\n",
    "# do this once\n",
    "np_load_old = np.load\n",
    "np.load = lambda *a,**k: np_load_old(*a, allow_pickle=True, **k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "sp_train = np.load(sp_data_path)\n",
    "wp_train = np.load(wp_data_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "507\n",
      "id SP-0\n",
      "question Mr. and Mrs. Mustard have six daughters and each daughter has one brother. But there are only 9 people in the family, how is that possible?\n",
      "answer Each daughter shares the same brother.\n",
      "distractor1 Some daughters get married and have their own family.\n",
      "distractor2 Some brothers were not loved by family and moved away.\n",
      "distractor(unsure) None of above.\n",
      "label 1\n",
      "choice_list ['Some daughters get married and have their own family.', 'Each daughter shares the same brother.', 'Some brothers were not loved by family and moved away.', 'None of above.']\n",
      "choice_order [1, 0, 2, 3]\n",
      "\n",
      "396\n",
      "id WP-0\n",
      "question How do you spell COW in thirteen letters?\n",
      "answer SEE O DOUBLE YOU.\n",
      "distractor1 COWCOWCOWCOWW\n",
      "distractor2 SEE OH DEREFORD\n",
      "distractor(unsure) None of above.\n",
      "label 1\n",
      "choice_list ['SEE OH DEREFORD', 'SEE O DOUBLE YOU.', 'COWCOWCOWCOWW', 'None of above.']\n",
      "choice_order [2, 0, 1, 3]\n"
     ]
    }
   ],
   "source": [
    "print(len(sp_train))\n",
    "for k, v in sp_train[0].items():\n",
    "    print(k, v)\n",
    "print()\n",
    "print(len(wp_train))\n",
    "for k, v in wp_train[0].items():\n",
    "    print(k, v)\n",
    "\n",
    "'''\n",
    "data has two ids \n",
    "SP = sentence puzzle, WP = word puzzle \n",
    "\n",
    "each data point has a question, an answer, and a list of the choices, \n",
    "a lable indicating the index of the correct choice, and a choice order (which we probably won't use)\n",
    "'''\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "config.json: 100%|██████████| 443/443 [00:00<00:00, 75.6kB/s]\n",
      "model.safetensors: 100%|██████████| 1.34G/1.34G [00:20<00:00, 65.1MB/s]\n",
      "Some weights of the model checkpoint at bert-large-uncased-whole-word-masking-finetuned-squad were not used when initializing BertForQuestionAnswering: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight']\n",
      "- This IS expected if you are initializing BertForQuestionAnswering from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForQuestionAnswering from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "tokenizer_config.json: 100%|██████████| 28.0/28.0 [00:00<00:00, 6.31kB/s]\n",
      "vocab.txt: 100%|██████████| 232k/232k [00:00<00:00, 1.46MB/s]\n",
      "tokenizer.json: 100%|██████████| 466k/466k [00:00<00:00, 3.24MB/s]\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "Trying out a pretrained BERT model for QA \n",
    "'''\n",
    "model = BertForQuestionAnswering.from_pretrained('bert-large-uncased-whole-word-masking-finetuned-squad')\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-large-uncased-whole-word-masking-finetuned-squad')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Start scores is an output of the same length as the context paragraph given, \n",
    "and each label indicates the probability that the answer starts at that word embedding\n",
    "'''\n",
    "\n",
    "question = sp_train[10]['question']\n",
    "paragraph = f\"A. {sp_train[10]['answer']}\\nB. {sp_train[10]['distractor1']}\\nC. {sp_train[10]['distractor2']}\\nD. {sp_train[10]['distractor(unsure)']}\"\n",
    "            \n",
    "encoding = tokenizer.encode_plus(text=question,text_pair=paragraph)\n",
    "inputs = encoding['input_ids']\n",
    "sentence_embedding = encoding['token_type_ids'] \n",
    "tokens = tokenizer.convert_ids_to_tokens(inputs) \n",
    "outputs = model(input_ids=torch.tensor([inputs]), token_type_ids=torch.tensor([sentence_embedding]))\n",
    "start_scores = outputs.start_logits\n",
    "end_scores = outputs.end_logits\n",
    "start_index = torch.argmax(start_scores)\n",
    "end_index = torch.argmax(end_scores)\n",
    "answer = ' '.join(tokens[start_index : end_index+1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def func(*list_input):\n",
    "    return sum(list_input)\n",
    "def func2(**dict_input):\n",
    "    # print(dict_input)\n",
    "    num_image = dict_input['num_image']\n",
    "    return num_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n"
     ]
    }
   ],
   "source": [
    "# print(func([1,2,3,4,5]))\n",
    "# print(func2({'wili':1, 'qq':2}))\n",
    "# print(func(1,2,3,4))\n",
    "model_name = \"adrgagjaopgkjpaokgpoar\"\n",
    "print(func2(num_image=10, model=model_name))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are five apples in a basket. You distribute them among the five girls, giving each one an apple while leaving one apple in the basket. How is that even doable?\n",
      "A. Give the fifth girl her apple in the basket.\n",
      "B. Two girls decide to share one apple.\n",
      "C. One girl is polite and return her apple back.\n",
      "D. None of above.\n",
      "give the fifth girl her apple in the basket .\n"
     ]
    }
   ],
   "source": [
    "print(question)\n",
    "print(paragraph)\n",
    "print(answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "question = wp_train[0]['question']\n",
    "paragraph = f\"A. {wp_train[0]['answer']}\\nB. {wp_train[0]['distractor1']}\\nC. {wp_train[0]['distractor2']}\\nD. {wp_train[0]['distractor(unsure)']}\"\n",
    "            \n",
    "encoding = tokenizer.encode_plus(text=question,text_pair=paragraph)\n",
    "inputs = encoding['input_ids']\n",
    "sentence_embedding = encoding['token_type_ids'] \n",
    "tokens = tokenizer.convert_ids_to_tokens(inputs) \n",
    "outputs = model(input_ids=torch.tensor([inputs]), token_type_ids=torch.tensor([sentence_embedding]))\n",
    "start_scores = outputs.start_logits\n",
    "end_scores = outputs.end_logits\n",
    "start_index = torch.argmax(start_scores)\n",
    "end_index = torch.argmax(end_scores)\n",
    "answer = ' '.join(tokens[start_index : end_index+1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['[CLS]', 'how', 'do', 'you', 'spell', 'cow', 'in', 'thirteen', 'letters', '?', '[SEP]', 'a', '.', 'see', 'o', 'double', 'you', '.', 'b', '.', 'cow', '##co', '##wc', '##ow', '##co', '##w', '##w', 'c', '.', 'see', 'oh', 'der', '##ef', '##ord', 'd', '.', 'none', 'of', 'above', '.', '[SEP]']\n",
      "How do you spell COW in thirteen letters?\n",
      "A. SEE O DOUBLE YOU.\n",
      "B. COWCOWCOWCOWW\n",
      "C. SEE OH DEREFORD\n",
      "D. None of above.\n"
     ]
    }
   ],
   "source": [
    "print(tokens)\n",
    "print(question)\n",
    "print(paragraph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cow ##co ##wc ##ow ##co ##w ##w\n"
     ]
    }
   ],
   "source": [
    "print(answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "question = wp_train[1]['question']\n",
    "paragraph = f\"A. {wp_train[1]['answer']}\\nB. {wp_train[1]['distractor1']}\\nC. {wp_train[1]['distractor2']}\\nD. {wp_train[1]['distractor(unsure)']}\"\n",
    "            \n",
    "encoding = tokenizer.encode_plus(text=question,text_pair=paragraph)\n",
    "inputs = encoding['input_ids']\n",
    "sentence_embedding = encoding['token_type_ids'] \n",
    "tokens = tokenizer.convert_ids_to_tokens(inputs) \n",
    "outputs = model(input_ids=torch.tensor([inputs]), token_type_ids=torch.tensor([sentence_embedding]))\n",
    "start_scores = outputs.start_logits\n",
    "end_scores = outputs.end_logits\n",
    "start_index = torch.argmax(start_scores)\n",
    "\n",
    "end_index = torch.argmax(end_scores)\n",
    "answer = ' '.join(tokens[start_index : end_index+1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['[CLS]', 'in', 'thirteen', 'letters', ',', 'how', 'do', 'you', 'spell', 'cow', '?', '[SEP]', 'a', '.', 'see', 'o', 'double', 'you', '.', 'b', '.', 'cow', '##co', '##wc', '##ow', '##co', '##w', '##w', 'c', '.', 'see', 'oh', 'der', '##ef', '##ord', 'd', '.', 'none', 'of', 'above', '.', '[SEP]']\n",
      "In thirteen letters, how do you spell COW?\n",
      "A. SEE O DOUBLE YOU.\n",
      "B. COWCOWCOWCOWW\n",
      "C. SEE OH DEREFORD\n",
      "D. None of above.\n"
     ]
    }
   ],
   "source": [
    "print(tokens)\n",
    "print(question)\n",
    "print(paragraph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cow ##co ##wc ##ow ##co ##w ##w\n"
     ]
    }
   ],
   "source": [
    "print(answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(wp_train[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "question = wp_train[5]['question']\n",
    "paragraph = f\"A. {wp_train[5]['answer']}\\nB. {wp_train[5]['distractor1']}\\nC. {wp_train[5]['distractor2']}\\nD. {wp_train[5]['distractor(unsure)']}\"\n",
    "            \n",
    "encoding = tokenizer.encode_plus(text=question,text_pair=paragraph)\n",
    "inputs = encoding['input_ids']\n",
    "sentence_embedding = encoding['token_type_ids'] \n",
    "tokens = tokenizer.convert_ids_to_tokens(inputs) \n",
    "outputs = model(input_ids=torch.tensor([inputs]), token_type_ids=torch.tensor([sentence_embedding]))\n",
    "start_scores = outputs.start_logits\n",
    "end_scores = outputs.end_logits\n",
    "start_index = torch.argmax(start_scores)\n",
    "\n",
    "end_index = torch.argmax(end_scores)\n",
    "answer = ' '.join(tokens[start_index : end_index+1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['[CLS]', 'what', 'does', 'eight', 'plus', 'three', 'equal', 'if', 'ten', 'plus', 'three', 'equals', 'one', '?', '[SEP]', 'a', '.', 'eleven', '.', 'b', '.', 'two', '.', 'c', '.', 'five', '.', 'd', '.', 'none', 'of', 'above', '.', '[SEP]']\n",
      "What does eight plus three equal if ten plus three equals one?\n",
      "A. Eleven.\n",
      "B. Two.\n",
      "C. Five.\n",
      "D. None of above.\n",
      "two . c . five\n"
     ]
    }
   ],
   "source": [
    "print(tokens)\n",
    "print(question)\n",
    "print(paragraph)\n",
    "print(answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
